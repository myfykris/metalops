# Metalops Benchmark Results

*Generated: 2026-01-07 21:03:04*

**Legend:** ðŸ’š GPU wins big (>3x) | ðŸŸ¢ GPU wins | ðŸ”µ Close | âšª CPU wins | ðŸŸ  CPU wins big (>3x)

## SVD (metalsvd)

*Singular Value Decomposition using Jacobi algorithm on GPU*

| Shape | Config | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 32Ã—32 | Tiny | 922.8Âµs | 78.4Âµs | 11.77x | ðŸŸ  | âœ“ 2e-06 |
| 64Ã—64 | Small square | 1.1ms | 229.1Âµs | 4.86x | ðŸŸ  | âœ“ 4e-06 |
| 128Ã—128 | Medium square | 1.7ms | 793.0Âµs | 2.08x | âšª | âœ“ 5e-06 |
| 256Ã—256 | Large square | 5.4ms | 4.1ms | 1.30x | âšª | âœ“ 7e-06 |
| 512Ã—512 | Very large | 14.4ms | 17.5ms | 0.83x | ðŸ”µ | âœ“ 9e-06 |
| 1024Ã—1024 | Huge square | 67.5ms | 86.6ms | 0.78x | ðŸ”µ | âœ“ 1e-05 |
| 2048Ã—2048 | Massive square | 341.0ms | 508.8ms | 0.67x | ðŸŸ¢ | âœ“ 2e-05 |
| 256Ã—128 | Tall 2:1 | 2.3ms | 1.7ms | 1.35x | âšª | âœ“ 6e-06 |
| 512Ã—256 | Tall 2:1 large | 7.3ms | 8.4ms | 0.87x | ðŸ”µ | âœ“ 9e-06 |
| 1024Ã—512 | Tall matrix | 14.8ms | 39.8ms | 0.37x | ðŸŸ¢ | âœ“ 9e-06 |
| 2048Ã—512 | Very tall | 15.3ms | 104.0ms | 0.15x | ðŸ’š | âœ“ 9e-06 |
| 128Ã—256 | Wide 1:2 | 2.5ms | 1.9ms | 1.34x | âšª | âœ“ 5e-06 |
| 4096Ã—4096 | Llama-7B attn (4096x4096) | 2.86s | 4.89s | 0.58x | ðŸŸ¢ | âœ“ 6e-05 |
| 4096Ã—11008 | Llama-2-7B MLP (4096x11008) | 2.92s | 11.82s | 0.25x | ðŸ’š | âœ“ 3e-05 |
| 4096Ã—14336 | Llama-3-8B MLP (4096x14336) | 2.99s | 17.09s | 0.18x | ðŸ’š | âœ“ 3e-05 |
| 8192Ã—8192 | Llama-70B attn (8192x8192) | 21.70s | 36.90s | 0.59x | ðŸŸ¢ | âœ“ 9e-05 |
| 4096Ã—14336 | Mistral-7B MLP (4096x14336) | 2.98s | 16.93s | 0.18x | ðŸ’š | âœ“ 3e-05 |
| 4096Ã—11008 | Qwen-7B MLP (4096x11008) | 2.91s | 11.67s | 0.25x | ðŸ’š | âœ“ 3e-05 |
| 3072Ã—24576 | Gemma-7B MLP (3072x24576) | 998.9ms | 28.26s | 0.04x | ðŸ’š | âœ“ 3e-05 |
| 3072Ã—8192 | Phi-3-mini MLP (3072x8192) | 939.4ms | 5.39s | 0.17x | ðŸ’š | âœ“ 3e-05 |
| 100Ã—32Ã—32 | Batch 100 tiny | 5.6ms | 7.2ms | 0.78x | ðŸ”µ | âœ“ 3e-06 |
| 50Ã—64Ã—64 | Batch 50 small | 6.3ms | 11.9ms | 0.53x | ðŸŸ¢ | âœ“ 6e-06 |
| 100Ã—64Ã—64 | Batch 100 small | 8.3ms | 23.6ms | 0.35x | ðŸŸ¢ | âœ“ 4e-06 |
| 200Ã—64Ã—64 | Batch 200 small | 14.1ms | 47.2ms | 0.30x | ðŸ’š | âœ“ 5e-06 |
| 20Ã—128Ã—128 | Batch 20 medium | 6.6ms | 16.6ms | 0.40x | ðŸŸ¢ | âœ“ 1e-05 |
| 50Ã—128Ã—128 | Batch 50 medium | 11.1ms | 41.2ms | 0.27x | ðŸ’š | âœ“ 1e-05 |
| 10Ã—256Ã—256 | Batch 10 large | 47.3ms | 44.7ms | 1.06x | ðŸ”µ | âœ“ 2e-05 |
| 5Ã—512Ã—512 | Batch 5 huge | 62.5ms | 89.4ms | 0.70x | ðŸŸ¢ | âœ“ 9e-06 |

## QR Single Matrix (metalcore)

*Single matrix QR - CPU typically wins due to sequential dependencies*

| Shape | Config | Metal | CPU | Ratio | Status | Recon | Ortho |
|---|---|---|---|---|---|---|---|
| 16Ã—16 | Tiny | 1.1ms | 46.3Âµs | 23.85x | ðŸŸ  | âœ“ 7e-07 | âœ“ 3e-07 |
| 32Ã—32 | Small 32 | 572.3Âµs | 60.2Âµs | 9.51x | ðŸŸ  | âœ“ 1e-06 | âœ“ 3e-07 |
| 64Ã—64 | Small 64 | 727.8Âµs | 86.7Âµs | 8.39x | ðŸŸ  | âœ“ 1e-06 | âœ“ 6e-07 |
| 128Ã—128 | Medium | 773.6Âµs | 282.6Âµs | 2.74x | âšª | âœ“ 3e-06 | âœ“ 6e-07 |
| 256Ã—256 | Large 256 | 2.0ms | 964.5Âµs | 2.05x | âšª | âœ“ 4e-06 | âœ“ 8e-07 |
| 512Ã—512 | Large 512 | 5.4ms | 4.3ms | 1.28x | ðŸ”µ | âœ“ 9e-06 | âœ“ 1e-06 |
| 1024Ã—1024 | Huge 1024 | 28.2ms | 25.2ms | 1.12x | ðŸ”µ | âœ“ 1e-05 | âœ“ 2e-06 |
| 256Ã—64 | Tall 4:1 | 1.3ms | 211.4Âµs | 6.29x | ðŸŸ  | âœ“ 2e-06 | âœ“ 5e-07 |
| 256Ã—128 | Tall 2:1 | 1.4ms | 576.4Âµs | 2.40x | âšª | âœ“ 4e-06 | âœ“ 7e-07 |
| 512Ã—128 | Tall 4:1 large | 1.9ms | 1.1ms | 1.76x | âšª | âœ“ 7e-06 | âœ“ 7e-07 |
| 512Ã—256 | Tall 2:1 large | 3.1ms | 2.1ms | 1.49x | âšª | âœ“ 6e-06 | âœ“ 1e-06 |
| 1000Ã—200 | Tall 5:1 | 3.7ms | 2.6ms | 1.44x | âšª | âœ“ 8e-06 | âœ“ 2e-06 |
| 2000Ã—500 | Huge tall | 16.3ms | 13.5ms | 1.20x | ðŸ”µ | âœ“ 2e-05 | âœ“ 2e-06 |
| 4000Ã—1000 | Massive | 82.5ms | 76.2ms | 1.08x | ðŸ”µ | âœ“ 2e-05 | âœ“ 3e-06 |

## QR Batched (metalcore) â­ GPU WINS

*Batched QR - GPU processes all matrices in parallel, single dispatch*

| Shape | Config | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 50Ã—8Ã—8 | Tiny 8x8 | 911.7Âµs | 2.1ms | 0.44x | ðŸŸ¢ | âœ“ 1e-06 |
| 100Ã—8Ã—8 | Batch 100 tiny | 867.2Âµs | 4.5ms | 0.19x | ðŸ’š | âœ“ 5e-07 |
| 500Ã—8Ã—8 | Batch 500 tiny | 1.4ms | 23.0ms | 0.06x | ðŸ’š | âœ“ 4e-07 |
| 50Ã—16Ã—16 | ML mini-batch 16 | 1.7ms | 2.4ms | 0.70x | ðŸŸ¢ | âœ“ 1e-06 |
| 100Ã—16Ã—16 | Batch 100 16x16 | 1.3ms | 5.0ms | 0.26x | ðŸ’š | âœ“ 1e-06 |
| 200Ã—16Ã—16 | Batch 200 16x16 | 1.7ms | 9.8ms | 0.17x | ðŸ’š | âœ“ 1e-06 |
| 500Ã—16Ã—16 | Batch 500 16x16 | 2.4ms | 24.2ms | 0.10x | ðŸ’š | âœ“ 6e-07 |
| 1000Ã—16Ã—16 | Batch 1000 16x16 | 3.9ms | 47.9ms | 0.08x | ðŸ’š | âœ“ 7e-07 |
| 50Ã—32Ã—32 | ML mini-batch 32 | 2.8ms | 2.7ms | 1.04x | ðŸ”µ | âœ“ 1e-06 |
| 100Ã—32Ã—32 | Batch 100 32x32 | 2.3ms | 5.5ms | 0.41x | ðŸŸ¢ | âœ“ 1e-06 |
| 200Ã—32Ã—32 | Batch 200 32x32 | 2.8ms | 11.0ms | 0.25x | ðŸ’š | âœ“ 1e-06 |
| 500Ã—32Ã—32 | Batch 500 32x32 | 6.3ms | 27.7ms | 0.23x | ðŸ’š | âœ“ 1e-06 |
| 50Ã—48Ã—48 | Batch 50 48x48 | 5.0ms | 3.4ms | 1.46x | âšª | âœ“ 1e-06 |
| 100Ã—48Ã—48 | Batch 100 48x48 | 4.9ms | 6.7ms | 0.74x | ðŸ”µ | âœ“ 2e-06 |
| 100Ã—64Ã—32 | Tall batch | 2.6ms | 6.0ms | 0.44x | ðŸŸ¢ | âœ“ 1e-06 |
| 100Ã—32Ã—64 | Wide batch | 3.9ms | 6.0ms | 0.65x | ðŸŸ¢ | âœ“ 1e-06 |
| 200Ã—64Ã—32 | Large tall batch | 4.4ms | 12.5ms | 0.35x | ðŸŸ¢ | âœ“ 2e-06 |

## Cholesky (metalcore) â­ GPU WINS

*Batched Cholesky decomposition with MAGMA-style shared memory*

| Shape | Config | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 100Ã—16Ã—16 | Tiny batched | 224.2Âµs | 4.4ms | 0.05x | ðŸ’š | âœ“ 8e-06 |
| 500Ã—16Ã—16 | Large batch tiny | 832.6Âµs | 23.3ms | 0.04x | ðŸ’š | âœ“ 8e-06 |
| 100Ã—32Ã—32 | Small batched | 841.7Âµs | 4.4ms | 0.19x | ðŸ’š | âœ“ 8e-06 |
| 200Ã—48Ã—48 | Medium batched | 849.5Âµs | 9.4ms | 0.09x | ðŸ’š | âœ“ 2e-05 |
| 100Ã—64Ã—64 | Larger batched | 1.0ms | 4.6ms | 0.23x | ðŸ’š | âœ“ 2e-05 |

## Linear Solve (metalcore)

*Batched linear system solve using QR + TRSM*

| Shape | Config | Metal | CPU | Ratio | Status | Residual |
|---|---|---|---|---|---|---|
| 100Ã—16Ã—16 | Tiny batched fp32 | 221.2Âµs | 1.3ms | 0.17x | ðŸ’š | ~ 3e-04 |
| 500Ã—16Ã—16 | Large batch tiny fp32 | 324.3Âµs | 6.2ms | 0.05x | ðŸ’š | ~ 2e-03 |
| 100Ã—32Ã—32 | Small batched fp32 | 601.4Âµs | 1.7ms | 0.36x | ðŸŸ¢ | ~ 3e-04 |
| 200Ã—48Ã—48 | Medium batched fp32 | 870.8Âµs | 4.1ms | 0.21x | ðŸ’š | ~ 8e-03 |

## Eigendecomposition (metaleig)

*Symmetric eigenvalue decomposition*

| Shape | Config | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 32Ã—32 | Tiny | 773.3Âµs | 52.3Âµs | 14.79x | ðŸŸ  | âœ“ 2e-06 |
| 64Ã—64 | Small | 899.5Âµs | 179.8Âµs | 5.00x | ðŸŸ  | âœ“ 3e-06 |
| 128Ã—128 | Medium | 1.5ms | 632.9Âµs | 2.43x | âšª | âœ“ 4e-06 |
| 256Ã—256 | Large | 3.9ms | 3.0ms | 1.30x | âšª | âœ“ 8e-06 |
| 512Ã—512 | Very large | 13.9ms | 12.1ms | 1.15x | ðŸ”µ | âœ“ 1e-05 |
| 1024Ã—1024 | Huge | 69.1ms | 65.9ms | 1.05x | ðŸ”µ | âœ“ 2e-05 |
| 100Ã—32Ã—32 | Batch 100 tiny | 5.7ms | 4.8ms | 1.20x | ðŸ”µ | âœ— 2e+00 |
| 50Ã—64Ã—64 | Batch 50 small | 4.6ms | 9.6ms | 0.47x | ðŸŸ¢ | ~ 5e-04 |
| 100Ã—64Ã—64 | Batch 100 small | 7.8ms | 17.8ms | 0.44x | ðŸŸ¢ | ~ 2e-03 |
| 200Ã—64Ã—64 | Batch 200 small | 13.5ms | 35.3ms | 0.38x | ðŸŸ¢ | ~ 9e-04 |
| 20Ã—128Ã—128 | Batch 20 medium | 5.5ms | 11.6ms | 0.48x | ðŸŸ¢ | ~ 8e-04 |
| 50Ã—128Ã—128 | Batch 50 medium | 9.1ms | 28.5ms | 0.32x | ðŸŸ¢ | ~ 7e-03 |
| 10Ã—256Ã—256 | Batch 10 large | 28.7ms | 27.0ms | 1.06x | ðŸ”µ | âœ“ 8e-06 |

## RMSNorm (metalcore) â­ GPU WINS

*Fused RMSNorm kernel vs torch.nn.RMSNorm*

| Shape | Config | Metal | CPU | Ratio | Status |
|---|---|---|---|---|---|
| 32x4096 | Fwd+Bwd fp32 | 440.3Âµs | 499.4Âµs | 0.88x | ðŸ”µ |
| 1x4096 | Fwd+Bwd fp32 | 427.3Âµs | 448.3Âµs | 0.95x | ðŸ”µ |
| 1024x1024 | Fwd+Bwd fp32 | 854.7Âµs | 932.4Âµs | 0.92x | ðŸ”µ |
| 4096x4096 | Fwd+Bwd fp32 | 6.0ms | 8.7ms | 0.68x | ðŸŸ¢ |

## AdamW (metalcore) â­ GPU WINS

*Fused AdamW optimizer step vs torch.optim.AdamW*

| Params | Size | Metal | CPU | Ratio | Status |
|---|---|---|---|---|---|
| 1M Params | N=1048576 fp32 | 298.6Âµs | 496.4Âµs | 0.60x | ðŸŸ¢ |
| 10M Params | N=10485760 fp32 | 1.1ms | 3.0ms | 0.37x | ðŸŸ¢ |
| 16M Params | N=16777216 fp32 | 1.7ms | 4.5ms | 0.37x | ðŸŸ¢ |

## Activations (metalcore)

*GELU/SiLU activations with float4 vectorization*

| Op | Shape | Metal | Torch | Ratio | Status |
|---|---|---|---|---|---|
| GELU Small (256x1024) | 256x1024 fp32 | 207.0Âµs | 210.8Âµs | 0.98x | ðŸ”µ |
| SiLU Small (256x1024) | 256x1024 fp32 | 187.6Âµs | 189.6Âµs | 0.99x | ðŸ”µ |
| GELU Medium (1024x4096) | 1024x4096 fp32 | 262.9Âµs | 246.8Âµs | 1.07x | ðŸ”µ |
| SiLU Medium (1024x4096) | 1024x4096 fp32 | 231.4Âµs | 261.6Âµs | 0.88x | ðŸ”µ |
| GELU Large (4096x4096) | 4096x4096 fp32 | 595.7Âµs | 605.4Âµs | 0.98x | ðŸ”µ |
| SiLU Large (4096x4096) | 4096x4096 fp32 | 607.9Âµs | 592.3Âµs | 1.03x | ðŸ”µ |

## SDPA (metalcore)

*Scaled Dot Product Attention with Flash Attention v2 tiling*

| Config | Shape | Metal | Torch | Ratio | Status | Error |
|---|---|---|---|---|---|---|
| Small (B=2, H=8, N=64, D=64) | B=2, H=8, N=64, D=64 fp32 | 254.1Âµs | 301.4Âµs | 0.84x | ðŸ”µ | âœ“ 1e-06 |
| Small (B=2, H=8, N=64, D=64) (causal) | B=2, H=8, N=64, D=64 fp32 | 671.4Âµs | 291.7Âµs | 2.30x | âšª | âœ“ 4e-06 |
| Medium (B=2, H=8, N=256, D=64) | B=2, H=8, N=256, D=64 fp32 | 902.8Âµs | 394.8Âµs | 2.29x | âšª | âœ— 1e-01 |
| Medium (B=2, H=8, N=256, D=64) (causal) | B=2, H=8, N=256, D=64 fp32 | 3.5ms | 398.7Âµs | 8.85x | ðŸŸ  | âœ“ 3e-06 |
| Large (B=1, H=8, N=512, D=64) | B=1, H=8, N=512, D=64 fp32 | 1.7ms | 457.6Âµs | 3.72x | ðŸŸ  | âœ— 4e-02 |
| Large (B=1, H=8, N=512, D=64) (causal) | B=1, H=8, N=512, D=64 fp32 | 6.0ms | 446.9Âµs | 13.44x | ðŸŸ  | âœ“ 3e-06 |

## Fused Softmax (metalcore)

*Online softmax algorithm with SIMD reductions*

| Config | Shape | Metal | Torch | Ratio | Status | Error |
|---|---|---|---|---|---|---|
| Small | 32x1024 fp32 | 151.6Âµs | 180.6Âµs | 0.84x | ðŸ”µ | 3.73e-09 |
| Medium | 64x4096 fp32 | 153.6Âµs | 201.4Âµs | 0.76x | ðŸ”µ | 1.40e-09 |
| Large | 128x8192 fp32 | 169.3Âµs | 202.6Âµs | 0.84x | ðŸ”µ | 9.31e-10 |
| Very Large | 256x16384 fp32 | 228.5Âµs | 292.8Âµs | 0.78x | ðŸ”µ | 9.31e-10 |
| Huge | 512x32768 fp32 | 908.7Âµs | 809.9Âµs | 1.12x | ðŸ”µ | 6.98e-10 |
| LLM Vocab | 32x32000 fp32 | 205.4Âµs | 234.4Âµs | 0.88x | ðŸ”µ | 2.33e-10 |
| LLM Vocab Large | 128x128000 fp32 | 915.4Âµs | 804.5Âµs | 1.14x | ðŸ”µ | 1.16e-10 |

## LayerNorm (metalcore)

*Welford's algorithm for fused mean/variance*

| Config | Shape | Metal | Torch | Ratio | Status | Error |
|---|---|---|---|---|---|---|
| Tiny | 32x512 fp32 | 162.1Âµs | 162.6Âµs | 1.00x | ðŸ”µ | 4.77e-07 |
| Small | 64x1024 fp32 | 184.5Âµs | 180.5Âµs | 1.02x | ðŸ”µ | 4.77e-07 |
| Llama-7B | 32x4096 fp32 | 193.3Âµs | 208.6Âµs | 0.93x | ðŸ”µ | 4.77e-07 |
| Llama-13B | 32x5120 fp32 | 175.0Âµs | 180.6Âµs | 0.97x | ðŸ”µ | 4.77e-07 |
| Llama-70B | 16x8192 fp32 | 180.6Âµs | 182.3Âµs | 0.99x | ðŸ”µ | 4.77e-07 |
| Large Batch | 256x4096 fp32 | 193.6Âµs | 207.1Âµs | 0.93x | ðŸ”µ | 4.77e-07 |
| Huge Batch | 1024x4096 fp32 | 257.7Âµs | 333.7Âµs | 0.77x | ðŸ”µ | 9.54e-07 |

## Embedding Bag (metalcore)

*Coalesced reads for embedding lookups and aggregation*

| Config | Shape | Metal | Torch | Ratio | Status |
|---|---|---|---|---|---|
| Small Vocab | 10000x64, B=32 | 248.9Âµs | 1.2ms | 0.21x | ðŸ’š |
| Medium Vocab | 50000x128, B=64 | 234.1Âµs | 1.6ms | 0.14x | ðŸ’š |
| Large Vocab | 100000x256, B=32 | 305.0Âµs | 8.5ms | 0.04x | ðŸ’š |
| LLM Embedding | 32000x4096, B=16 | 316.3Âµs | 20.8ms | 0.02x | ðŸ’š |
| Huge Vocab | 250000x512, B=16 | 253.7Âµs | 19.2ms | 0.01x | ðŸ’š |

## Scatter/Gather (metalcore)

*Atomic scatter_add and vectorized gather operations*

| Op | Shape | Metal | Torch | Ratio | Status |
|---|---|---|---|---|---|
| Gather Small | src=10000, idx=1000 | 209.5Âµs | 230.6Âµs | 0.91x | ðŸ”µ |
| Gather Medium | src=100000, idx=10000 | 204.1Âµs | 217.3Âµs | 0.94x | ðŸ”µ |
| Gather Large | src=1000000, idx=100000 | 217.3Âµs | 249.3Âµs | 0.87x | ðŸ”µ |
| Gather Huge | src=10000000, idx=1000000 | 355.8Âµs | 360.7Âµs | 0.99x | ðŸ”µ |
| ScatterAdd Small | dst=10000, idx=1000 | 214.6Âµs | 244.5Âµs | 0.88x | ðŸ”µ |
| ScatterAdd Medium | dst=100000, idx=10000 | 240.5Âµs | 264.0Âµs | 0.91x | ðŸ”µ |
| ScatterAdd Large | dst=1000000, idx=100000 | 251.8Âµs | 264.9Âµs | 0.95x | ðŸ”µ |
| ScatterAdd Huge | dst=10000000, idx=1000000 | 960.7Âµs | 993.4Âµs | 0.97x | ðŸ”µ |

## Pipeline Operations â­ GPU WINS (No Transfer)

*Chained operations where data stays on GPU - avoids costly memory transfers*

| Pipeline | Shape | GPU | Comparison | Ratio | Status |
|---|---|---|---|---|---|
| QR -> QR -> QR | 200Ã—32Ã—32 | 8.2ms | 31.8ms | 0.26x | ðŸ’š |
| SVD -> truncate (PCA) | 50Ã—128Ã—64 | 10.5ms | 16.0ms | 0.66x | ðŸŸ¢ |
| QR -> matmul (ML) | 1000Ã—16Ã—16 | 5.5ms | 52.1ms | 0.11x | ðŸ’š |
| Fast+Slow+Fast (GPU all) | 200Ã—32Ã—32 | 5.1ms | 3.2ms | 1.59x vs hybrid | ðŸŸ  |
| Fast+Slow+Fast (vs CPU) | 200Ã—32Ã—32 | 5.1ms | 12.1ms | 0.42x vs CPU | ðŸŸ¢ |

## LLM: Llama

*SVD performance on Llama weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 4096Ã—4096 | Attention (7B) | 2.88s | 5.02s | 0.57x | ðŸŸ¢ | âœ“ 3e-05 |
| 4096Ã—11008 | MLP up (7B) | 2.93s | 9.93s | 0.30x | ðŸ’š | âœ“ 3e-05 |
| 8192Ã—8192 | Attention (70B) | 21.35s | 36.82s | 0.58x | ðŸŸ¢ | âœ“ 9e-05 |

## LLM: Mistral

*SVD performance on Mistral weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 4096Ã—4096 | Attention | 2.86s | 4.97s | 0.57x | ðŸŸ¢ | âœ“ 3e-05 |
| 4096Ã—14336 | MLP up | 2.99s | 11.68s | 0.26x | ðŸ’š | âœ“ 4e-05 |

## LLM: Qwen

*SVD performance on Qwen weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 4096Ã—4096 | Attention | 2.87s | 5.03s | 0.57x | ðŸŸ¢ | âœ“ 3e-05 |
| 4096Ã—11008 | MLP up | 2.92s | 10.11s | 0.29x | ðŸ’š | âœ“ 4e-05 |

## LLM: Gemma

*SVD performance on Gemma weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 3072Ã—3072 | Attention | 936.9ms | 1.57s | 0.60x | ðŸŸ¢ | ~ 1e-04 |
| 3072Ã—24576 | MLP up | 1.00s | 9.24s | 0.11x | ðŸ’š | âœ“ 3e-05 |

## LLM: Phi

*SVD performance on Phi weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 3072Ã—3072 | Attention | 928.4ms | 1.60s | 0.58x | ðŸŸ¢ | ~ 2e-04 |
| 3072Ã—8192 | MLP up | 944.1ms | 3.68s | 0.26x | ðŸ’š | âœ“ 2e-05 |

## Usage Recommendations

| Operation | When to Use Metal | When to Use CPU |
|---|---|---|
| SVD | Batched small/medium matrices | Single large matrices |
| QR (single) | â€” | Always (sequential dependencies) |
| QR (batched) | Many small matrices (10x speedup!) | Few matrices |
| EIGH | Batched symmetric matrices | Single large matrices |
| Pipeline | Keep data on GPU to avoid transfer cost | Single ops on CPU-resident data |
