# Metalops Benchmark Results

*Generated: 2026-01-07 18:19:55*

**Legend:** ðŸ’š GPU wins big (>3x) | ðŸŸ¢ GPU wins | ðŸ”µ Close | âšª CPU wins | ðŸŸ  CPU wins big (>3x)

## SVD (metalsvd)

*Singular Value Decomposition using Jacobi algorithm on GPU*

| Shape | Config | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 32Ã—32 | Tiny | 1.4ms | 80.3Âµs | 17.90x | ðŸŸ  | âœ“ 3e-06 |
| 64Ã—64 | Small square | 1.1ms | 226.1Âµs | 5.00x | ðŸŸ  | âœ“ 3e-06 |
| 128Ã—128 | Medium square | 1.6ms | 783.0Âµs | 2.10x | âšª | âœ“ 5e-06 |
| 256Ã—256 | Large square | 5.3ms | 4.0ms | 1.33x | âšª | âœ“ 8e-06 |
| 512Ã—512 | Very large | 14.1ms | 17.9ms | 0.79x | ðŸ”µ | âœ“ 9e-06 |
| 1024Ã—1024 | Huge square | 68.7ms | 90.0ms | 0.76x | ðŸ”µ | âœ“ 1e-05 |
| 2048Ã—2048 | Massive square | 341.1ms | 526.4ms | 0.65x | ðŸŸ¢ | âœ“ 2e-05 |
| 256Ã—128 | Tall 2:1 | 3.2ms | 1.7ms | 1.88x | âšª | âœ“ 5e-06 |
| 512Ã—256 | Tall 2:1 large | 7.1ms | 8.2ms | 0.87x | ðŸ”µ | âœ“ 1e-05 |
| 1024Ã—512 | Tall matrix | 14.1ms | 43.2ms | 0.33x | ðŸŸ¢ | âœ“ 9e-06 |
| 2048Ã—512 | Very tall | 15.3ms | 103.5ms | 0.15x | ðŸ’š | âœ“ 9e-06 |
| 128Ã—256 | Wide 1:2 | 3.2ms | 1.9ms | 1.74x | âšª | âœ“ 7e-06 |
| 4096Ã—4096 | Llama-7B attn (4096x4096) | 2.87s | 5.11s | 0.56x | ðŸŸ¢ | âœ“ 6e-05 |
| 4096Ã—11008 | Llama-2-7B MLP (4096x11008) | 2.96s | 11.87s | 0.25x | ðŸ’š | âœ“ 3e-05 |
| 4096Ã—14336 | Llama-3-8B MLP (4096x14336) | 2.97s | 17.17s | 0.17x | ðŸ’š | âœ“ 3e-05 |
| 8192Ã—8192 | Llama-70B attn (8192x8192) | 22.02s | 37.14s | 0.59x | ðŸŸ¢ | âœ“ 9e-05 |
| 4096Ã—14336 | Mistral-7B MLP (4096x14336) | 2.98s | 17.17s | 0.17x | ðŸ’š | âœ“ 4e-05 |
| 4096Ã—11008 | Qwen-7B MLP (4096x11008) | 2.94s | 11.98s | 0.25x | ðŸ’š | âœ“ 3e-05 |
| 3072Ã—24576 | Gemma-7B MLP (3072x24576) | 1.00s | 28.30s | 0.04x | ðŸ’š | âœ“ 2e-05 |
| 3072Ã—8192 | Phi-3-mini MLP (3072x8192) | 933.1ms | 5.27s | 0.18x | ðŸ’š | âœ“ 2e-05 |
| 100Ã—32Ã—32 | Batch 100 tiny | 5.7ms | 6.9ms | 0.83x | ðŸ”µ | âœ“ 3e-06 |
| 50Ã—64Ã—64 | Batch 50 small | 5.8ms | 11.6ms | 0.50x | ðŸŸ¢ | âœ“ 7e-06 |
| 100Ã—64Ã—64 | Batch 100 small | 8.6ms | 23.3ms | 0.37x | ðŸŸ¢ | âœ“ 7e-06 |
| 200Ã—64Ã—64 | Batch 200 small | 15.4ms | 46.2ms | 0.33x | ðŸŸ¢ | âœ“ 5e-06 |
| 20Ã—128Ã—128 | Batch 20 medium | 7.2ms | 16.0ms | 0.45x | ðŸŸ¢ | âœ“ 8e-06 |
| 50Ã—128Ã—128 | Batch 50 medium | 10.7ms | 40.0ms | 0.27x | ðŸ’š | âœ“ 1e-05 |
| 10Ã—256Ã—256 | Batch 10 large | 46.9ms | 40.8ms | 1.15x | ðŸ”µ | âœ“ 2e-05 |
| 5Ã—512Ã—512 | Batch 5 huge | 60.7ms | 87.8ms | 0.69x | ðŸŸ¢ | âœ“ 8e-06 |

## QR Single Matrix (metalcore)

*Single matrix QR - CPU typically wins due to sequential dependencies*

| Shape | Config | Metal | CPU | Ratio | Status | Recon | Ortho |
|---|---|---|---|---|---|---|---|
| 16Ã—16 | Tiny | 1.3ms | 53.0Âµs | 24.95x | ðŸŸ  | âœ“ 5e-07 | âœ“ 6e-07 |
| 32Ã—32 | Small 32 | 702.7Âµs | 58.4Âµs | 12.04x | ðŸŸ  | âœ“ 1e-06 | âœ“ 3e-07 |
| 64Ã—64 | Small 64 | 788.7Âµs | 87.8Âµs | 8.98x | ðŸŸ  | âœ“ 2e-06 | âœ“ 5e-07 |
| 128Ã—128 | Medium | 905.9Âµs | 262.4Âµs | 3.45x | ðŸŸ  | âœ“ 3e-06 | âœ“ 7e-07 |
| 256Ã—256 | Large 256 | 1.8ms | 921.7Âµs | 1.92x | âšª | âœ“ 4e-06 | âœ“ 6e-07 |
| 512Ã—512 | Large 512 | 5.4ms | 4.1ms | 1.32x | âšª | âœ“ 9e-06 | âœ“ 1e-06 |
| 1024Ã—1024 | Huge 1024 | 26.7ms | 23.8ms | 1.12x | ðŸ”µ | âœ“ 1e-05 | âœ“ 2e-06 |
| 256Ã—64 | Tall 4:1 | 1.6ms | 248.0Âµs | 6.40x | ðŸŸ  | âœ“ 2e-06 | âœ“ 6e-07 |
| 256Ã—128 | Tall 2:1 | 1.3ms | 579.9Âµs | 2.22x | âšª | âœ“ 5e-06 | âœ“ 7e-07 |
| 512Ã—128 | Tall 4:1 large | 1.8ms | 1.0ms | 1.77x | âšª | âœ“ 5e-06 | âœ“ 1e-06 |
| 512Ã—256 | Tall 2:1 large | 2.9ms | 1.9ms | 1.54x | âšª | âœ“ 9e-06 | âœ“ 1e-06 |
| 1000Ã—200 | Tall 5:1 | 3.8ms | 2.6ms | 1.45x | âšª | âœ“ 9e-06 | âœ“ 1e-06 |
| 2000Ã—500 | Huge tall | 15.4ms | 13.2ms | 1.17x | ðŸ”µ | âœ“ 2e-05 | âœ“ 2e-06 |
| 4000Ã—1000 | Massive | 79.4ms | 73.1ms | 1.09x | ðŸ”µ | âœ“ 3e-05 | âœ“ 3e-06 |

## QR Batched (metalcore) â­ GPU WINS

*Batched QR - GPU processes all matrices in parallel, single dispatch*

| Shape | Config | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 50Ã—8Ã—8 | Tiny 8x8 | 653.1Âµs | 2.1ms | 0.31x | ðŸŸ¢ | âœ“ 1e-06 |
| 100Ã—8Ã—8 | Batch 100 tiny | 727.7Âµs | 4.3ms | 0.17x | ðŸ’š | âœ“ 4e-07 |
| 500Ã—8Ã—8 | Batch 500 tiny | 1.6ms | 22.2ms | 0.07x | ðŸ’š | âœ“ 5e-07 |
| 50Ã—16Ã—16 | ML mini-batch 16 | 1.3ms | 2.3ms | 0.56x | ðŸŸ¢ | âœ“ 7e-07 |
| 100Ã—16Ã—16 | Batch 100 16x16 | 1.5ms | 4.7ms | 0.32x | ðŸŸ¢ | âœ“ 8e-07 |
| 200Ã—16Ã—16 | Batch 200 16x16 | 1.6ms | 9.3ms | 0.17x | ðŸ’š | âœ“ 7e-07 |
| 500Ã—16Ã—16 | Batch 500 16x16 | 2.9ms | 23.1ms | 0.13x | ðŸ’š | âœ“ 1e-06 |
| 1000Ã—16Ã—16 | Batch 1000 16x16 | 3.5ms | 47.2ms | 0.07x | ðŸ’š | âœ“ 7e-07 |
| 50Ã—32Ã—32 | ML mini-batch 32 | 2.9ms | 2.8ms | 1.06x | ðŸ”µ | âœ“ 2e-06 |
| 100Ã—32Ã—32 | Batch 100 32x32 | 2.3ms | 5.3ms | 0.44x | ðŸŸ¢ | âœ“ 1e-06 |
| 200Ã—32Ã—32 | Batch 200 32x32 | 2.9ms | 10.6ms | 0.28x | ðŸ’š | âœ“ 1e-06 |
| 500Ã—32Ã—32 | Batch 500 32x32 | 6.2ms | 26.5ms | 0.23x | ðŸ’š | âœ“ 1e-06 |
| 50Ã—48Ã—48 | Batch 50 48x48 | 4.9ms | 3.2ms | 1.52x | âšª | âœ“ 1e-06 |
| 100Ã—48Ã—48 | Batch 100 48x48 | 4.9ms | 6.4ms | 0.77x | ðŸ”µ | âœ“ 1e-06 |
| 100Ã—64Ã—32 | Tall batch | 2.6ms | 6.0ms | 0.43x | ðŸŸ¢ | âœ“ 1e-06 |
| 100Ã—32Ã—64 | Wide batch | 3.7ms | 5.7ms | 0.65x | ðŸŸ¢ | âœ“ 1e-06 |
| 200Ã—64Ã—32 | Large tall batch | 4.5ms | 11.9ms | 0.38x | ðŸŸ¢ | âœ“ 1e-06 |

## Cholesky (metalcore) â­ GPU WINS

*Batched Cholesky decomposition with MAGMA-style shared memory*

| Shape | Config | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 100Ã—16Ã—16 | Tiny batched | 830.9Âµs | 4.3ms | 0.19x | ðŸ’š | âœ“ 6e-06 |
| 500Ã—16Ã—16 | Large batch tiny | 702.5Âµs | 21.1ms | 0.03x | ðŸ’š | âœ“ 6e-06 |
| 100Ã—32Ã—32 | Small batched | 876.6Âµs | 4.3ms | 0.21x | ðŸ’š | âœ“ 8e-06 |
| 200Ã—48Ã—48 | Medium batched | 910.5Âµs | 8.7ms | 0.11x | ðŸ’š | âœ“ 8e-06 |
| 100Ã—64Ã—64 | Larger batched | 930.5Âµs | 4.4ms | 0.21x | ðŸ’š | âœ“ 2e-05 |

## Linear Solve (metalcore)

*Batched linear system solve using QR + TRSM*

| Shape | Config | Metal | CPU | Ratio | Status | Residual |
|---|---|---|---|---|---|---|
| 100Ã—16Ã—16 | Tiny batched fp32 | 705.1Âµs | 1.1ms | 0.62x | ðŸŸ¢ | ~ 1e-04 |
| 500Ã—16Ã—16 | Large batch tiny fp32 | 745.9Âµs | 5.7ms | 0.13x | ðŸ’š | ~ 6e-04 |
| 100Ã—32Ã—32 | Small batched fp32 | 1.3ms | 1.6ms | 0.83x | ðŸ”µ | ~ 1e-03 |
| 200Ã—48Ã—48 | Medium batched fp32 | 1.7ms | 4.0ms | 0.43x | ðŸŸ¢ | ~ 9e-04 |

## Eigendecomposition (metaleig)

*Symmetric eigenvalue decomposition*

| Shape | Config | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 32Ã—32 | Tiny | 745.0Âµs | 48.6Âµs | 15.31x | ðŸŸ  | âœ“ 2e-06 |
| 64Ã—64 | Small | 810.1Âµs | 176.4Âµs | 4.59x | ðŸŸ  | âœ“ 2e-06 |
| 128Ã—128 | Medium | 1.1ms | 556.0Âµs | 2.02x | âšª | âœ“ 4e-06 |
| 256Ã—256 | Large | 3.9ms | 2.7ms | 1.48x | âšª | âœ“ 9e-06 |
| 512Ã—512 | Very large | 13.9ms | 11.9ms | 1.16x | ðŸ”µ | âœ“ 1e-05 |
| 1024Ã—1024 | Huge | 67.4ms | 64.8ms | 1.04x | ðŸ”µ | âœ“ 2e-05 |
| 100Ã—32Ã—32 | Batch 100 tiny | 6.4ms | 4.7ms | 1.35x | âšª | âœ— 3e+00 |
| 50Ã—64Ã—64 | Batch 50 small | 4.6ms | 8.8ms | 0.52x | ðŸŸ¢ | ~ 5e-04 |
| 100Ã—64Ã—64 | Batch 100 small | 7.9ms | 17.8ms | 0.45x | ðŸŸ¢ | ~ 2e-04 |
| 200Ã—64Ã—64 | Batch 200 small | 14.1ms | 35.4ms | 0.40x | ðŸŸ¢ | ~ 5e-04 |
| 20Ã—128Ã—128 | Batch 20 medium | 5.4ms | 11.3ms | 0.48x | ðŸŸ¢ | ~ 3e-04 |
| 50Ã—128Ã—128 | Batch 50 medium | 9.5ms | 28.0ms | 0.34x | ðŸŸ¢ | ~ 6e-03 |
| 10Ã—256Ã—256 | Batch 10 large | 27.9ms | 25.6ms | 1.09x | ðŸ”µ | âœ“ 6e-06 |

## RMSNorm (metalcore) â­ GPU WINS

*Fused RMSNorm kernel vs torch.nn.RMSNorm*

| Shape | Config | Metal | CPU | Ratio | Status |
|---|---|---|---|---|---|
| 32x4096 | Fwd+Bwd fp32 | 580.5Âµs | 488.2Âµs | 1.19x | ðŸ”µ |
| 1x4096 | Fwd+Bwd fp32 | 511.8Âµs | 429.8Âµs | 1.19x | ðŸ”µ |
| 1024x1024 | Fwd+Bwd fp32 | 946.5Âµs | 923.8Âµs | 1.02x | ðŸ”µ |
| 4096x4096 | Fwd+Bwd fp32 | 6.2ms | 8.6ms | 0.72x | ðŸ”µ |

## AdamW (metalcore) â­ GPU WINS

*Fused AdamW optimizer step vs torch.optim.AdamW*

| Params | Size | Metal | CPU | Ratio | Status |
|---|---|---|---|---|---|
| 1M Params | N=1048576 fp32 | 324.5Âµs | 499.7Âµs | 0.65x | ðŸŸ¢ |
| 10M Params | N=10485760 fp32 | 1.1ms | 2.9ms | 0.37x | ðŸŸ¢ |
| 16M Params | N=16777216 fp32 | 1.6ms | 4.5ms | 0.36x | ðŸŸ¢ |

## Activations (metalcore)

*GELU/SiLU activations with float4 vectorization*

| Op | Shape | Metal | Torch | Ratio | Status |
|---|---|---|---|---|---|
| GELU Small (256x1024) | 256x1024 fp32 | 185.2Âµs | 184.3Âµs | 1.00x | ðŸ”µ |
| SiLU Small (256x1024) | 256x1024 fp32 | 154.4Âµs | 148.2Âµs | 1.04x | ðŸ”µ |
| GELU Medium (1024x4096) | 1024x4096 fp32 | 231.5Âµs | 225.3Âµs | 1.03x | ðŸ”µ |
| SiLU Medium (1024x4096) | 1024x4096 fp32 | 220.8Âµs | 213.7Âµs | 1.03x | ðŸ”µ |
| GELU Large (4096x4096) | 4096x4096 fp32 | 567.6Âµs | 565.8Âµs | 1.00x | ðŸ”µ |
| SiLU Large (4096x4096) | 4096x4096 fp32 | 558.1Âµs | 578.7Âµs | 0.96x | ðŸ”µ |

## SDPA (metalcore)

*Scaled Dot Product Attention with Flash Attention v2 tiling*

| Config | Shape | Metal | Torch | Ratio | Status | Error |
|---|---|---|---|---|---|---|
| Small (B=2, H=8, N=64, D=64) | B=2, H=8, N=64, D=64 fp32 | 192.0Âµs | 228.1Âµs | 0.84x | ðŸ”µ | âœ“ 9e-07 |
| Small (B=2, H=8, N=64, D=64) (causal) | B=2, H=8, N=64, D=64 fp32 | 613.9Âµs | 278.4Âµs | 2.21x | âšª | âœ“ 3e-06 |
| Medium (B=2, H=8, N=256, D=64) | B=2, H=8, N=256, D=64 fp32 | 862.1Âµs | 352.8Âµs | 2.44x | âšª | âœ— 5e-02 |
| Medium (B=2, H=8, N=256, D=64) (causal) | B=2, H=8, N=256, D=64 fp32 | 3.4ms | 383.7Âµs | 8.97x | ðŸŸ  | âœ“ 4e-06 |
| Large (B=1, H=8, N=512, D=64) | B=1, H=8, N=512, D=64 fp32 | 1.6ms | 436.1Âµs | 3.74x | ðŸŸ  | âœ— 5e-02 |
| Large (B=1, H=8, N=512, D=64) (causal) | B=1, H=8, N=512, D=64 fp32 | 6.0ms | 463.2Âµs | 12.86x | ðŸŸ  | âœ“ 3e-06 |

## Fused Softmax (metalcore)

*Online softmax algorithm with SIMD reductions*

| Config | Shape | Metal | Torch | Ratio | Status | Error |
|---|---|---|---|---|---|---|
| Small | 32x1024 fp32 | 155.3Âµs | 180.2Âµs | 0.86x | ðŸ”µ | 3.73e-09 |
| Medium | 64x4096 fp32 | 152.8Âµs | 182.2Âµs | 0.84x | ðŸ”µ | 1.86e-09 |
| Large | 128x8192 fp32 | 164.5Âµs | 213.0Âµs | 0.77x | ðŸ”µ | 9.31e-10 |
| Very Large | 256x16384 fp32 | 262.4Âµs | 279.2Âµs | 0.94x | ðŸ”µ | 4.66e-10 |
| Huge | 512x32768 fp32 | 948.5Âµs | 833.0Âµs | 1.14x | ðŸ”µ | 3.49e-10 |
| LLM Vocab | 32x32000 fp32 | 202.7Âµs | 228.4Âµs | 0.89x | ðŸ”µ | 2.33e-10 |
| LLM Vocab Large | 128x128000 fp32 | 945.0Âµs | 830.8Âµs | 1.14x | ðŸ”µ | 1.16e-10 |

## LayerNorm (metalcore)

*Welford's algorithm for fused mean/variance*

| Config | Shape | Metal | Torch | Ratio | Status | Error |
|---|---|---|---|---|---|---|
| Tiny | 32x512 fp32 | 166.0Âµs | 164.0Âµs | 1.01x | ðŸ”µ | 4.77e-07 |
| Small | 64x1024 fp32 | 165.9Âµs | 159.6Âµs | 1.04x | ðŸ”µ | 4.77e-07 |
| Llama-7B | 32x4096 fp32 | 164.8Âµs | 168.7Âµs | 0.98x | ðŸ”µ | 4.77e-07 |
| Llama-13B | 32x5120 fp32 | 172.9Âµs | 166.3Âµs | 1.04x | ðŸ”µ | 4.77e-07 |
| Llama-70B | 16x8192 fp32 | 173.9Âµs | 165.7Âµs | 1.05x | ðŸ”µ | 9.54e-07 |
| Large Batch | 256x4096 fp32 | 188.4Âµs | 185.8Âµs | 1.01x | ðŸ”µ | 9.54e-07 |
| Huge Batch | 1024x4096 fp32 | 256.4Âµs | 256.6Âµs | 1.00x | ðŸ”µ | 7.15e-07 |

## Embedding Bag (metalcore)

*Coalesced reads for embedding lookups and aggregation*

| Config | Shape | Metal | Torch | Ratio | Status |
|---|---|---|---|---|---|
| Small Vocab | 10000x64, B=32 | 215.7Âµs | 1.2ms | 0.18x | ðŸ’š |
| Medium Vocab | 50000x128, B=64 | 221.0Âµs | 1.6ms | 0.14x | ðŸ’š |
| Large Vocab | 100000x256, B=32 | 233.8Âµs | 6.6ms | 0.04x | ðŸ’š |
| LLM Embedding | 32000x4096, B=16 | 353.9Âµs | 18.7ms | 0.02x | ðŸ’š |
| Huge Vocab | 250000x512, B=16 | 244.7Âµs | 17.1ms | 0.01x | ðŸ’š |

## Scatter/Gather (metalcore)

*Atomic scatter_add and vectorized gather operations*

| Op | Shape | Metal | Torch | Ratio | Status |
|---|---|---|---|---|---|
| Gather Small | src=10000, idx=1000 | 186.1Âµs | 191.6Âµs | 0.97x | ðŸ”µ |
| Gather Medium | src=100000, idx=10000 | 180.8Âµs | 192.3Âµs | 0.94x | ðŸ”µ |
| Gather Large | src=1000000, idx=100000 | 203.9Âµs | 223.9Âµs | 0.91x | ðŸ”µ |
| Gather Huge | src=10000000, idx=1000000 | 331.0Âµs | 344.5Âµs | 0.96x | ðŸ”µ |
| ScatterAdd Small | dst=10000, idx=1000 | 207.7Âµs | 220.3Âµs | 0.94x | ðŸ”µ |
| ScatterAdd Medium | dst=100000, idx=10000 | 209.0Âµs | 222.7Âµs | 0.94x | ðŸ”µ |
| ScatterAdd Large | dst=1000000, idx=100000 | 240.4Âµs | 257.9Âµs | 0.93x | ðŸ”µ |
| ScatterAdd Huge | dst=10000000, idx=1000000 | 935.5Âµs | 986.2Âµs | 0.95x | ðŸ”µ |

## Pipeline Operations â­ GPU WINS (No Transfer)

*Chained operations where data stays on GPU - avoids costly memory transfers*

| Pipeline | Shape | GPU | Comparison | Ratio | Status |
|---|---|---|---|---|---|
| QR -> QR -> QR | 200Ã—32Ã—32 | 8.1ms | 31.6ms | 0.26x | ðŸ’š |
| SVD -> truncate (PCA) | 50Ã—128Ã—64 | 9.7ms | 15.8ms | 0.61x | ðŸŸ¢ |
| QR -> matmul (ML) | 1000Ã—16Ã—16 | 4.0ms | 50.4ms | 0.08x | ðŸ’š |
| Fast+Slow+Fast (GPU all) | 200Ã—32Ã—32 | 4.8ms | 3.7ms | 1.29x vs hybrid | ðŸŸ  |
| Fast+Slow+Fast (vs CPU) | 200Ã—32Ã—32 | 4.8ms | 11.9ms | 0.40x vs CPU | ðŸŸ¢ |

## LLM: Llama

*SVD performance on Llama weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 4096Ã—4096 | Attention (7B) | 2.85s | 5.04s | 0.57x | ðŸŸ¢ | âœ“ 3e-05 |
| 4096Ã—11008 | MLP up (7B) | 2.94s | 10.12s | 0.29x | ðŸ’š | âœ“ 3e-05 |
| 8192Ã—8192 | Attention (70B) | 21.50s | 37.15s | 0.58x | ðŸŸ¢ | âœ“ 5e-05 |

## LLM: Mistral

*SVD performance on Mistral weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 4096Ã—4096 | Attention | 2.84s | 4.95s | 0.57x | ðŸŸ¢ | âœ“ 3e-05 |
| 4096Ã—14336 | MLP up | 2.94s | 11.71s | 0.25x | ðŸ’š | âœ“ 3e-05 |

## LLM: Qwen

*SVD performance on Qwen weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 4096Ã—4096 | Attention | 2.84s | 4.97s | 0.57x | ðŸŸ¢ | âœ“ 3e-05 |
| 4096Ã—11008 | MLP up | 2.90s | 9.99s | 0.29x | ðŸ’š | âœ“ 3e-05 |

## LLM: Gemma

*SVD performance on Gemma weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 3072Ã—3072 | Attention | 929.5ms | 1.56s | 0.60x | ðŸŸ¢ | âœ“ 3e-05 |
| 3072Ã—24576 | MLP up | 991.0ms | 9.25s | 0.11x | ðŸ’š | âœ“ 3e-05 |

## LLM: Phi

*SVD performance on Phi weight matrix sizes*

| Shape | Layer | Metal | CPU | Ratio | Status | Recon Error |
|---|---|---|---|---|---|---|
| 3072Ã—3072 | Attention | 922.3ms | 1.55s | 0.60x | ðŸŸ¢ | âœ“ 2e-05 |
| 3072Ã—8192 | MLP up | 941.7ms | 3.78s | 0.25x | ðŸ’š | âœ“ 2e-05 |

## Usage Recommendations

| Operation | When to Use Metal | When to Use CPU |
|---|---|---|
| SVD | Batched small/medium matrices | Single large matrices |
| QR (single) | â€” | Always (sequential dependencies) |
| QR (batched) | Many small matrices (10x speedup!) | Few matrices |
| EIGH | Batched symmetric matrices | Single large matrices |
| Pipeline | Keep data on GPU to avoid transfer cost | Single ops on CPU-resident data |
